{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf933767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25-11-23\n",
    "# CSC461 – Assignment3 – Machine Learning\n",
    "# Maryam Yousaf\n",
    "# FA21-BSE-077\n",
    "# Question 1 to 4 Machine Learning Algorithm with different validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b0cd121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Provide responses to the following questions about the dataset.\n",
    "# 1. How many instances does the dataset contain?\n",
    "# A1. 110\n",
    "\n",
    "# 2. How many input attributes does the dataset contain?\n",
    "# A2. 7 height,weight,beard,hairlength,shoesize,scarf,eye-colour\n",
    "\n",
    "# 3. How many possible values does the output attribute have?\n",
    "# A3. 2 Male,Female\n",
    "\n",
    "# 4. How many input attributes are categorical?\n",
    "# A4. 4 beard,hairlength,scarf,eye-colour\n",
    "\n",
    "# 5. What is the class ratio (male vs female) in the dataset\n",
    "# A5. Male Ratio: No.of Male/ Total Instances 62/110 = 0.56\n",
    "#     Female ratio: No.of Females/Total Instances 48/110 = 0.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97e91c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-plot in c:\\users\\92321\\appdata\\roaming\\python\\python311\\site-packages (0.3.7)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-plot) (3.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-plot) (1.3.0)\n",
      "Requirement already satisfied: scipy>=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-plot) (1.10.1)\n",
      "Requirement already satisfied: joblib>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-plot) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->scikit-plot) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Q2: Apply Logistic Regression, Support Vector Machines, and Multilayer Perceptron classification  algorithms (using Python) on the gender prediction dataset with 2/3 train and 1/3 test split ratio and answer the following questions\n",
    "# 1. How many instances are incorrectly classified?\n",
    "!pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d731f0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     height  weight beard hair_length  shoe_size scarf eye_color  gender\n",
      "0        71     176   yes       short         44    no     black    male\n",
      "1        68     165    no        bald         41    no     black    male\n",
      "2        62     132    no      medium         37   yes      blue  female\n",
      "3        65     138    no        long         38    no      gray  female\n",
      "4        70     197   yes      medium         43    no      gray    male\n",
      "..      ...     ...   ...         ...        ...   ...       ...     ...\n",
      "105      61     103    no        long         38    no     green  female\n",
      "106      68     135    no        long         37   yes     green  female\n",
      "107      66     140    no        long         36   yes      gray  female\n",
      "108      66     132    no      medium         37    no     black  female\n",
      "109      70     160    no        long         42    no     black    male\n",
      "\n",
      "[110 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#import ML evaluation metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, model_selection\n",
    "# for question 3\n",
    "from sklearn.model_selection import ShuffleSplit,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeavePOut\n",
    "\n",
    "\n",
    "#import scikitplot to plot confusion matrix\n",
    "\n",
    "import scikitplot as skplt\n",
    "data = pd.read_csv('gender-prediction.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca2ba194",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('gender', axis=1)  #input\n",
    "y = data['gender']               #output\n",
    "#print(x)\n",
    "#print(y)   seperate input attributes from output\n",
    "labels = preprocessing.LabelEncoder()\n",
    "for column in data.columns:\n",
    "    # Check if the column dtype is object categorical\n",
    "    if data[column].dtype == 'object':\n",
    "        # then convert it into numerical\n",
    "        data[column] = labels.fit_transform(data[column])\n",
    "#x_encoded = labels.fit_transform(x)\n",
    "y_encoded = labels.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a0f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 2/3 train-test split:\n",
      "Logistic Regression Accuracy: 94.5945945945946\n",
      "Results for 2/3 train-test split:\n",
      "MultiLayer Perception Accuracy: 51.35135135135135\n"
     ]
    }
   ],
   "source": [
    "X_train, x_test, Y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "model1 = LogisticRegression(max_iter=1000)\n",
    "model2 = MLPClassifier(max_iter=1000, random_state=42)  #max iteration set to 1000 in order to avoid the error and setting random seed to make the initialization reproducible across runs.\n",
    "model1.fit(X_train,Y_train)\n",
    "prediction1 = model1.predict(x_test)\n",
    "logic_acc = accuracy_score(y_test, prediction1)*100\n",
    "print(\"Results for 2/3 train-test split:\")\n",
    "print(\"Logistic Regression Accuracy:\", logic_acc)\n",
    "model2.fit(X_train,Y_train)\n",
    "prediction2 = model2.predict(x_test)\n",
    "MLP_acc = accuracy_score(y_test, prediction2)*100\n",
    "print(\"Results for 2/3 train-test split:\")\n",
    "print(\"MultiLayer Perception Accuracy:\", MLP_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af56e606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 2/3 train-test split:\n",
      "Support Vector Machine Accuracy: 75.67567567567568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train,Y_train)\n",
    "prediction3 = svm_model.predict(x_test)\n",
    "SVM_acc = accuracy_score(y_test, prediction3)*100\n",
    "print(\"Results for 2/3 train-test split:\")\n",
    "print(\"Support Vector Machine Accuracy:\", SVM_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15967d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrectly Classified Instance using 67/33 split Logical regression: 5\n",
      "Incorrectly Classified Instance using 67/33 split Support Vector Machine: 24\n",
      "Incorrectly Classified Instance using 67/33 split MultiLayer Preception: 48\n"
     ]
    }
   ],
   "source": [
    "incorrectly_classified1 =  (100 - logic_acc)\n",
    "incorrectly_classified2 = (100 - MLP_acc)\n",
    "incorrectly_classified3 = (100 - SVM_acc)\n",
    "print(\"Incorrectly Classified Instance using 67/33 split Logical regression:\", int(incorrectly_classified1))\n",
    "print(\"Incorrectly Classified Instance using 67/33 split Support Vector Machine:\", int(incorrectly_classified3))\n",
    "print(\"Incorrectly Classified Instance using 67/33 split MultiLayer Preception:\", int(incorrectly_classified2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86d8db0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 80/20 train-test split:\n",
      "Logistic Regression Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "# 2. Rerun the experiment using train/test split ratio of 80/20. Do you see any change in the results? Explain\n",
    "# A2. yes change is noticable, increasing the size of train set can help the model generalize to unseen data \n",
    "#     therefore, The number of instances incorrectly classified is affected by size of the testing set. A smaller testing set may lead to more variability in the evaluation metric.\n",
    "X_train2, x_test2, Y_train2, y_test2 = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "model_L = LogisticRegression(max_iter =1000)\n",
    "model_L.fit(X_train2,Y_train2)\n",
    "prediction_L = model_L.predict(x_test2)\n",
    "logic_L_acc = accuracy_score(y_test2, prediction_L)*100\n",
    "print(\"Results for 80/20 train-test split:\")\n",
    "print(\"Logistic Regression Accuracy:\", logic_L_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "146c6866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 80/20 train-test split:\n",
      "MultiLayer Perception Accuracy: 45.45454545454545\n"
     ]
    }
   ],
   "source": [
    "model_M = MLPClassifier(max_iter=1000, random_state=42) \n",
    "model_M.fit(X_train2,Y_train2)\n",
    "prediction_M = model_M.predict(x_test2)\n",
    "MLP1_acc = accuracy_score(y_test2, prediction_M)*100\n",
    "print(\"Results for 80/20 train-test split:\")\n",
    "print(\"MultiLayer Perception Accuracy:\", MLP1_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a95bd7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 80/20 train-test split:\n",
      "Support Vector Machine Accuracy: 81.81818181818183\n",
      "Incorrectly Classified Instance using 80/20 split Logical regression: 0\n",
      "Incorrectly Classified Instance using 80/20 split Support Vector Machine: 54\n",
      "Incorrectly Classified Instance using 80/20 split MultiLayer Preception: 18\n"
     ]
    }
   ],
   "source": [
    "svm_model1 = SVC()\n",
    "svm_model1.fit(X_train2,Y_train2)\n",
    "prediction_S_3 = svm_model1.predict(x_test2)\n",
    "SVM1_acc = accuracy_score(y_test2, prediction_S_3)*100\n",
    "print(\"Results for 80/20 train-test split:\")\n",
    "print(\"Support Vector Machine Accuracy:\", SVM1_acc)\n",
    "incorrectly_classified4 =  (100 - logic_L_acc)\n",
    "incorrectly_classified5 = (100 - MLP1_acc)\n",
    "incorrectly_classified6 = (100 - SVM1_acc)\n",
    "print(\"Incorrectly Classified Instance using 80/20 split Logical regression:\", int(incorrectly_classified4))\n",
    "print(\"Incorrectly Classified Instance using 80/20 split Support Vector Machine:\", int(incorrectly_classified5))\n",
    "print(\"Incorrectly Classified Instance using 80/20 split MultiLayer Preception:\", int(incorrectly_classified6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7533fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Name 2 attributes that you believe are the most “powerful” in the prediction task. Explain why?\n",
    "# A3. Beard and Scarf are the most powerful in gender prediction task as Beards are more commonly associated with males and scarf with females\n",
    "# The ability to detect and analyze the presence of beard and scarf can serve as a powerful feature for gender prediction.Models trained on factors, including the presence or absence of a beard or scarf, can learn patterns that distinguish between male and female individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29300daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Try to exclude these 2 attribute(s) from the dataset. Rerun the experiment (using 80/20 train/test split),did you find any change in the results? Explain\n",
    "# A4. if the number decresed then indeed the attribute were essential for prediction but in this case model perform similarly because the dropped attributes were causing overfitting\n",
    "X = data.drop(['beard', 'scarf','gender'], axis=1)\n",
    "Y = data['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1b2977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = preprocessing.LabelEncoder()\n",
    "for column in data.columns:\n",
    "    # Check if the column dtype is object categorical\n",
    "    if data[column].dtype == 'object':\n",
    "        # then convert it into numerical\n",
    "        data[column] = label.fit_transform(data[column])\n",
    "#x_encoded = labels.fit_transform(x)\n",
    "y_encoded = label.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e686a786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 80/20 train-test split:\n",
      "Logistic Regression Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "X_train3, x_test3, Y_train3, y_test3 = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "model_L1 = LogisticRegression(max_iter =1000)\n",
    "model_L1.fit(X_train3,Y_train3)\n",
    "prediction_L1 = model_L1.predict(x_test3)\n",
    "logic_L_acc1 = accuracy_score(y_test3, prediction_L1)*100\n",
    "print(\"Results for 80/20 train-test split:\")\n",
    "print(\"Logistic Regression Accuracy:\", logic_L_acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ef1d20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 80/20 train-test split:\n",
      "MultiLayer Perception Accuracy: 45.45454545454545\n"
     ]
    }
   ],
   "source": [
    "model_M1 = MLPClassifier(max_iter=1000, random_state=42) \n",
    "model_M1.fit(X_train3,Y_train3)\n",
    "prediction_M1 = model_M1.predict(x_test3)\n",
    "MLP1_acc1 = accuracy_score(y_test3, prediction_M1)*100\n",
    "print(\"Results for 80/20 train-test split:\")\n",
    "print(\"MultiLayer Perception Accuracy:\", MLP1_acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "871736b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 80/20 train-test split:\n",
      "Support Vector Machine Accuracy: 81.81818181818183\n",
      "Incorrectly Classified Instance using 67/33 split Logical regression: 0\n",
      "Incorrectly Classified Instance using 67/33 split Support Vector Machine: 54\n",
      "Incorrectly Classified Instance using 67/33 split MultiLayer Preception: 18\n"
     ]
    }
   ],
   "source": [
    "svm_model2 = SVC()\n",
    "svm_model2.fit(X_train3,Y_train3)\n",
    "prediction_S_4 = svm_model2.predict(x_test3)\n",
    "SVM1_acc2 = accuracy_score(y_test3, prediction_S_4)*100\n",
    "print(\"Results for 80/20 train-test split:\")\n",
    "print(\"Support Vector Machine Accuracy:\", SVM1_acc2)\n",
    "incorrectly_classified7 =  (100 - logic_L_acc1)\n",
    "incorrectly_classified8 = (100 - MLP1_acc1)\n",
    "incorrectly_classified9 = (100 - SVM1_acc2)\n",
    "print(\"Incorrectly Classified Instance using 67/33 split Logical regression:\", int(incorrectly_classified7))\n",
    "print(\"Incorrectly Classified Instance using 67/33 split Support Vector Machine:\", int(incorrectly_classified8))\n",
    "print(\"Incorrectly Classified Instance using 67/33 split MultiLayer Preception:\", int(incorrectly_classified9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2f33a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Question 4 using Gaussian Naïve Bayes classification algorithm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "new_data = pd.read_csv('gender-prediction-update.csv')\n",
    "m = new_data.drop('gender', axis=1)\n",
    "n = new_data['gender']\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "for k in m.columns:\n",
    "    if m[k].dtype == 'object':\n",
    "        m[k] = label_encoder.fit_transform(m[k])\n",
    "    \n",
    "n_encoded = label_encoder.fit_transform(n)\n",
    "\n",
    "M_train, m_test, N_train, n_test = train_test_split(m, n, test_size=10, random_state=42)\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(M_train, N_train) # Train model using all instances\n",
    "n_pred = classifier.predict(m_test) # prediction on 10 instances\n",
    "\n",
    "accuracy = accuracy_score(n_test, n_pred)\n",
    "precision = precision_score(n_test, n_pred, average='weighted')\n",
    "recall = recall_score(n_test, n_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "798c0e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: F1 Score = 0.9743589743589743\n",
      "Iteration 2: F1 Score = 0.9473684210526315\n",
      "Iteration 3: F1 Score = 0.9767441860465117\n",
      "Iteration 4: F1 Score = 1.0\n",
      "Iteration 5: F1 Score = 0.9767441860465117\n",
      "\n",
      "Average F1 Score Across Iterations: 0.9750431535009259\n"
     ]
    }
   ],
   "source": [
    "# Question 3 Apply Random Forest classification algorithm (using Python) on the gender prediction dataset with Monte \n",
    "# Carlo cross-validation and Leave P-Out cross-validation. Report F1 scores for both cross-validation strategies\n",
    "random_model = RandomForestClassifier()\n",
    "split = ShuffleSplit(test_size = 0.33,train_size = 0.67,n_splits = 5,random_state = 42)   # use standard 2/3 and 1/3 split\n",
    "f1_scores = cross_val_score(random_model, x, y, cv=split, scoring='f1')\n",
    "for iteration, f1 in enumerate(f1_scores, start=1):\n",
    "    print(f\"Iteration {iteration}: F1 Score = {f1}\")\n",
    "average_f1 = sum(f1_scores) / len(f1_scores)      # take an average of f1 score \n",
    "print(f\"\\nAverage F1 Score Across Iterations: {average_f1}\")   \n",
    "# Result indicate the model has a high balance between precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "637d69b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_iteration = 5\n",
    "leave_p_out = LeavePOut(p_iteration)\n",
    "f1_scores1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ac540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in leave_p_out.split(x):\n",
    "    X_train, x_test = x.iloc[i], x.iloc[j]\n",
    "    Y_train, y_test = y.iloc[i], y.iloc[j]\n",
    "\n",
    "    random_model.fit(X_train, Y_train)\n",
    "    y_pred = random_model.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred,zero_division = 1)\n",
    "    f1_scores1.append(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, f1 in enumerate(f1_scores1, start=1):\n",
    "    print(f\"Iteration {item}: F1 Score = {f1}\")\n",
    "\n",
    "Paverage_f1 = sum(f1_scores1) / len(f1_scores1) if len(f1_scores1) > 0 else 0\n",
    "print(f\"\\nLeave P-out Average F1 Score Across Iterations: {Paverage_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47711a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
